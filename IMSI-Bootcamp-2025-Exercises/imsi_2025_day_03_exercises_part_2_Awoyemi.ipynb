{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SH5behQNLERg"
   },
   "source": [
    "## Exercise 5: #YOLO ALMA\n",
    "\n",
    "\n",
    "**Warning: This problem will take a variable amount of time to setup depending on the time of day!**\n",
    "\n",
    "In this exercise, we'll try to classify everyday objects from the\n",
    "[Alma webcam](https://illinois.edu/about/almacam.html) using the [You Only Look Once (YOLO) v11](https://docs.ultralytics.com/yolov11/).\n",
    "\n",
    "(Fun fact, there's another web camera on the quad called \"[the Quadcam](https://illinois.edu/about/quadcam.html)\", but the resolution is problematic with this algorithm.)\n",
    "\n",
    "Prior to beginning this problem, please make sure that a **GPU is enabled** by going to:\n",
    "\n",
    "```\n",
    "Runtime -> Change runtime type -> Hardware Accelerator -> GPU\n",
    "```\n",
    "\n",
    "Next, please run the following setup code to setup the environment for predicting with YOLO v11. In-depth instructions follow immediately after the setup code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVn4-8P7NvHO"
   },
   "source": [
    "## Setup Code\n",
    "\n",
    "Please run each code chunk in order. Failure to do so may result in issues when trying to detect an image with YOLO v11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2gd_uCGDXHR"
   },
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxkrKzWbDYwC"
   },
   "source": [
    "The YOLO model is very popular and there are a variety of different implementations. The implementation we'll use is [highly maintained](https://github.com/ultralytics/ultralytics) and [available on PyPI](https://pypi.org/project/ultralytics/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tb9R9VDsNvHP"
   },
   "outputs": [],
   "source": [
    "# Suppress output\n",
    "%%capture\n",
    "\n",
    "# 1. Install required dependencies from PyPi\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kspTSZpVC9Jk"
   },
   "source": [
    "### Initialize Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BE8vcyt_C_6R"
   },
   "source": [
    "Instead of training a model to fit, we'll use a pretrained version of YOLOv11 on the [COCO data set](https://cocodataset.org/#home) with the following [possible classes](https://github.com/ultralytics/ultralytics/blob/9f4eb2491b6a25abaae29b74da6698cefe8dc662/ultralytics/cfg/datasets/coco.yaml) available to use to classify objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqbIJMPVNvHP"
   },
   "outputs": [],
   "source": [
    "# 2. Retrieve and load the pretrained model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nw46tZ4etC1"
   },
   "source": [
    "### Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QO3jeFOoNvHT"
   },
   "source": [
    "Consider the following image from a UIUC blog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "89Ez-b8BNvHT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://blogs.illinois.edu/files/6231/545166/117021.jpg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://blogs.illinois.edu/files/6231/545166/117021.jpg', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1rUEc5gNvHT"
   },
   "source": [
    "The YOLOv11 algorithm could be used by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saTlNR2dNvHT"
   },
   "outputs": [],
   "source": [
    "# Importing cv2 (OpenCV [Computer Vision] library)\n",
    "import cv2\n",
    "\n",
    "# Patch the cv2.imshow() function (for Google Colab only)\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Predict on an image\n",
    "results = model('https://blogs.illinois.edu/files/6231/545166/117021.jpg', iou = 0.7, conf = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_tHSimrfkI5"
   },
   "source": [
    "Visually, we can see the predictions alongside of the bounding boxes by graphing the resulting frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjPRRmP-film"
   },
   "outputs": [],
   "source": [
    "for result in results:\n",
    "  # This automatically draws bounding boxes, labels, and confidence scores\n",
    "  annotated_frame = result.plot()\n",
    "\n",
    "  # Display bounding (required fix for Colab)\n",
    "  # will error if run locally\n",
    "  cv2_imshow(annotated_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Y5giGbDRrWL"
   },
   "source": [
    "For our prediction statement, we're receiving the `results` object that contains the following\n",
    "\n",
    "- `boxes.xyxy`: Bounding box regions of where the object detected lies\n",
    "  - e.g. blue boxes in the above image\n",
    "- `boxes.cls`: Class identifiers of objects detected in the above image.\n",
    "  - e.g. `0 -> \"person\"`, `26 -> \"umbrella\"`\n",
    "- `boxes.conf`: Probabilities of the different classes the model was trained for.\n",
    "  - e.g. the blue numeric values in the above image (e.g. bottom-left is 0.30)\n",
    "- `names`: All possible labels of objects\n",
    "  - e.g. the names (e.g. `'person'`, `'bicycle'`, `'car'`) as a value and the id (e.g. `0`, `1`, `2`) as a key in a dictionary.\n",
    "\n",
    "From the above variables, we are only interested in the `boxes.cls` and `names` variables. In particular, we want to know how many items were detected in the image via `boxes.cls` and the class that was detected, `names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VloFo1SWFZvg"
   },
   "outputs": [],
   "source": [
    "print(\"Bounding Box Coordinates (xmin, ymin, xmax, ymax)\")\n",
    "print(results[0].boxes.xyxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVllKvlb-usq"
   },
   "outputs": [],
   "source": [
    "print(\"Classes detected\")\n",
    "print(results[0].boxes.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foFdYPKs8ypw"
   },
   "outputs": [],
   "source": [
    "print(\"List of classes possible\")\n",
    "print(results[0].names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yZfPDuX_CHZ"
   },
   "source": [
    "## (a) Organizing Data\n",
    "\n",
    "For this exercise, we're looking to create a Pandas data frame that translates the predictions from being stored in an object with multiple dictionaries and lists into a single data frame. For simplicity, we'll use example image and its `results` object.\n",
    "\n",
    "We would like the data frame to have the following structure:\n",
    "\n",
    "| classid | classname|   xmin |   ymin |   xmax |   ymax |\n",
    "|--------:|:---------|-------:|-------:|-------:|-------:|\n",
    "|       0 | person   |    582 |    643 |    642 |    786 |\n",
    "|       0 | person   |    651 |    580 |    713 |    763 |\n",
    "|       0 | person   |    376 |    560 |    438 |    720 |\n",
    "|      25 | umbrella |    209 |    442 |    318 |    468 |\n",
    "|       0 | person   |     73 |    641 |    151 |    785 |\n",
    "\n",
    "We can retrieve the necessary items from `results` with:\n",
    "\n",
    "- `results[0].names`: dictionary of _possible_ class names\n",
    "- `results[0].boxes.cls`: predicted class IDs from the image\n",
    "- `results[0].boxes.xyxy`: predicted bounding box coordinates where:\n",
    "  - `results[0].boxes.xyxy[0]`: predicted `xmin` values\n",
    "  - `results[0].boxes.xyxy[1]`: predicted `ymin` values\n",
    "  - `results[0].boxes.xyxy[2]`: predicted `xmax` values\n",
    "  - `results[0].boxes.xyxy[3]`: predicted `ymax` values\n",
    "\n",
    "**Hint:** You may wish to use a list comprehension or a `for` loop to cycle the predicted object data contained in the results object.\n",
    "\n",
    "**Hint:** You may wish to also explicitly cast each value as an integer. You will want to explicitly cast `classid` as an integer before attempting to subset from the data frame, e.g. `results[0].names[int(classid)]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0vhfjxUAML6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def organized_yolo_df(results):\n",
    "  # Implement logic here\n",
    "  pass\n",
    "\n",
    "\n",
    "df = organized_yolo_df(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LkU38KcNvHS"
   },
   "source": [
    "## (b) Detecting Objects\n",
    "\n",
    "In this exercise, we're interested in detecting within images from the Alma mater webcam these object classes:\n",
    "\n",
    "- person\n",
    "- bicycle\n",
    "- backpack\n",
    "- handbag\n",
    "- cell phone\n",
    "\n",
    "Please use the spelling given above as it matches with classes recognized by the YoloV11 network (see [coco.yaml](https://github.com/ultralytics/ultralytics/blob/9f4eb2491b6a25abaae29b74da6698cefe8dc662/ultralytics/cfg/datasets/coco.yaml) for details.)\n",
    "\n",
    "Obtain the images from:\n",
    "\n",
    " - https://coatless.github.io/alma-cam/alma-cam-1.png\n",
    " - https://coatless.github.io/alma-cam/alma-cam-2.png\n",
    " - https://coatless.github.io/alma-cam/alma-cam-3.png\n",
    " - https://coatless.github.io/alma-cam/alma-cam-4.png\n",
    " - https://coatless.github.io/alma-cam/alma-cam-5.png\n",
    " - https://coatless.github.io/alma-cam/alma-cam-6.png\n",
    " - https://coatless.github.io/alma-cam/alma-cam-7.png\n",
    " - https://coatless.github.io/alma-cam/alma-cam-8.png\n",
    " - https://coatless.github.io/alma-cam/alma-cam-9.png\n",
    " - https://coatless.github.io/alma-cam/alma-cam-10.png\n",
    "\n",
    "So, the first image can be retrieved with:\n",
    "\n",
    "```\n",
    "https://coatless.github.io/alma-cam/alma-cam-1.png\n",
    "```\n",
    "\n",
    "Dynamically construct a Pandas dataframe that contains the ImageID and a count of each object under the given class. e.g.\n",
    "\n",
    "| ImageID    | person | bicycle | backpack | handbag | cell phone   |\n",
    "|:-----------|--------|---------|----------|---------|--------------|\n",
    "| example-1  | 0      |     1   | 1        | 0       |    0         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwhISDSENis2"
   },
   "source": [
    "For all of our URLs, under the default settings of `0.7` for `iou` and `0.25` for `conf`, we would expect to have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9_Ne9fINhUC"
   },
   "source": [
    "| ImageID     |   person |   bicycle |   backpack |   handbag |   cell phone |\n",
    "|:------------|---------:|----------:|-----------:|----------:|-------------:|\n",
    "| alma-cam-1  |       12 |         0 |          0 |         0 |            0 |\n",
    "| alma-cam-2  |        5 |         0 |          0 |         0 |            0 |\n",
    "| alma-cam-3  |        3 |         0 |          0 |         0 |            0 |\n",
    "| alma-cam-4  |        5 |         0 |          0 |         0 |            0 |\n",
    "| alma-cam-5  |        9 |         0 |          0 |         0 |            0 |\n",
    "| alma-cam-6  |       11 |         0 |          0 |         0 |            0 |\n",
    "| alma-cam-7  |       17 |         0 |          0 |         0 |            0 |\n",
    "| alma-cam-8  |       12 |         0 |          0 |         0 |            0 |\n",
    "| alma-cam-9  |        9 |         0 |          0 |         0 |            0 |\n",
    "| alma-cam-10 |       11 |         0 |          0 |         0 |            0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAgf2EbHNoBW"
   },
   "source": [
    "To help in this endeavor, we suggest using the function designed in part **(a)** to isolate the `classnames` for each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbU15WEPNvHU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Generate a list of problem URLs\n",
    "url_base = \"https://coatless.github.io/alma-cam/\"\n",
    "urls = [f\"{url_base}/alma-cam-{i}.png\" for i in range(1, 11)]\n",
    "\n",
    "# This makes urls have between 1 and 10:\n",
    "# https://coatless.github.io/alma-cam/alma-cam-1.png\n",
    "\n",
    "# List of classes\n",
    "# Important: These names _must_ match with what is specified in coco.yaml.\n",
    "classes_to_count = ['person', 'bicycle', 'backpack', 'handbag', 'cell phone']\n",
    "\n",
    "## code here\n",
    "def yolo_classifications(urls, classes_to_count):\n",
    "  # Pre-populate a data frame\n",
    "  cols = ['ImageID'] + classes_to_count\n",
    "  df = pd.DataFrame(columns = cols)\n",
    "\n",
    "  # Process each image\n",
    "  for i, url in enumerate(urls):\n",
    "    # Extract image ID from URL (e.g., \"alma-cam-1\")\n",
    "    image_id = Path(url).stem\n",
    "\n",
    "    print(f\"Processing {image_id}...\")\n",
    "\n",
    "    ## Implement logic here ##\n",
    "\n",
    "    # 1. Make prediction on the image\n",
    "    # results = ???? #\n",
    "\n",
    "    # 2. Get the organized DataFrame for this image's detections\n",
    "    # detection_df = organized_yolo_df(results)\n",
    "\n",
    "    # 3. Initialize counts for all classes\n",
    "\n",
    "    # 4. Count occurrences of each class of interest\n",
    "\n",
    "    # 5. Create row data for this image\n",
    "\n",
    "    # 6. Add to the main dataframe\n",
    "\n",
    "  pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUjsDVpnNvHU"
   },
   "source": [
    "## (c) Upload and run your own image!\n",
    "\n",
    "In this exercise, you will repeat the prior exercise but instead you will select the classes that should be detected from an image you supply.\n",
    "\n",
    "View all possible classes by exploring the `results[0].names` possible class name list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZT73P2ZNvHU"
   },
   "outputs": [],
   "source": [
    "# Upload an image file\n",
    "from google.colab import files\n",
    "uploaded_image = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cILfdTU8RYh7"
   },
   "source": [
    "Running the next line of code, should embed the uploaded image inside of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Va2b7OucNvHU"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Display the embedded image in the notebook.\n",
    "Image(uploaded_image[0], width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WD1V9d--H561"
   },
   "source": [
    "Apply the functions developed in **(a)** and **(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3EJRJ7TH6ky"
   },
   "outputs": [],
   "source": [
    "# Modify classes for unique values\n",
    "classes_to_count = ['person', 'bicycle', 'backpack', 'handbag', 'cell phone']\n",
    "\n",
    "yolo_classifications(uploaded_image, classes_to_count)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "244px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
